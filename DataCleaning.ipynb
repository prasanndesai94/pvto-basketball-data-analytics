{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasanndesai94/pvto-basketball-data-analytics/blob/main/DataCleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-1IKmPWAsu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3d11e8-9dea-4a83-cc68-2142662e8a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting html-table-parser-python3\n",
            "  Downloading html_table_parser_python3-0.3.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: html-table-parser-python3\n",
            "Successfully installed html-table-parser-python3-0.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.5-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.8/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "#need to have these installed before running this code\n",
        "!pip install html-table-parser-python3\n",
        "!pip install xlsxwriter\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBQqAfFFCWTt",
        "outputId": "74d2b676-a667-4dce-db47-28f450498b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request #gets content from turbostats\n",
        "from html_table_parser.parser import HTMLTableParser #extract table data from turbostats\n",
        "import pandas as pd #helps clean the data\n",
        "import numpy as np #used to flip for opposing team stats as necessary\n",
        "\n",
        "#opens a site and read HTTP for turbostats\n",
        "def url_get_contents(link):\n",
        "    #making request to the website to access data\n",
        "    request_link = urllib.request.Request(url=link)\n",
        "    content = urllib.request.urlopen(request_link)\n",
        "\n",
        "    #reading contents from the website\n",
        "    return content.read()\n",
        "  \n",
        "#NEED TO OPTIMIZE THIS FUNCTION!!!\n",
        "#reorder the columns in the dataset to make it easier to code\n",
        "def dataset(game: str):\n",
        "  site = 'https://www.turbostatsevents.com/site/2/boxscore/basketball/pioneervalleytipoff/'\n",
        "\n",
        "  #modify the year variable for when the event is taking place\n",
        "  year = '2022'\n",
        "\n",
        "  #defining the HTMLTableParser class object and feed the html parser from the function above. \n",
        "  #using this, we are able to use the .tables feature to extract the tables from Turbostats\n",
        "  retrive = HTMLTableParser()\n",
        "\n",
        "  #using .decode() here helps convert the html contents into useable data\n",
        "  retrive.feed(url_get_contents(site+year+'/'+game).decode('utf-8'))\n",
        "\n",
        "  #the two teams from each game. on turbostats, team1 is the team you see first\n",
        "  #on boxscore and team2 is 2nd team on boxscore\n",
        "  team1 = retrive.tables[0][1][0]\n",
        "  team2 = retrive.tables[0][2][0]\n",
        "\n",
        "  #extracting the data from the first team\n",
        "  players_team1_df = pd.DataFrame(retrive.tables[1])\n",
        "  players_team1_df.rename(columns=players_team1_df.iloc[0], inplace = True)\n",
        "  players_team1_df.drop(0,axis=0,inplace = True)\n",
        "  players_team1_df.insert(0,'Team',team1)\n",
        "  players_team1_df.drop('Net', axis=1, inplace=True)\n",
        "\n",
        "  #extracting data from the second team\n",
        "  players_team2_df = pd.DataFrame(retrive.tables[2])\n",
        "  players_team2_df.rename(columns=players_team2_df.iloc[0], inplace = True)\n",
        "  players_team2_df.drop(0,axis=0,inplace = True)\n",
        "  players_team2_df.insert(0,'Team',team2)\n",
        "  players_team2_df.drop('Net', axis=1, inplace=True)\n",
        "\n",
        "  #took each of the teams from each game and combined them together\n",
        "  game_data = pd.concat([players_team1_df, players_team2_df], axis=0)\n",
        "\n",
        "  #we will separate out the player and team totals to have two datasets, which\n",
        "  #are player and team datasets. this will help as we can analyze on a holisitc\n",
        "  #level from each team and on a micro level, which is the players data.\n",
        "\n",
        "  #this is the team results from each game\n",
        "  game_results = game_data[game_data[\"Name\"] == \"Totals\"]\n",
        "  game_results = game_results.reset_index(drop=True)\n",
        "  game_results.loc[0,'Name'] = team1\n",
        "  game_results.loc[1,'Name'] = team2\n",
        "  #dropping +- since it's not that useful in a team context\n",
        "  game_results.drop(['Number', 'Team', '+-'], axis=1, inplace=True)\n",
        "\n",
        "  #this is the players stats from each game\n",
        "  game_data = game_data[(game_data[\"Name\"] != \"Totals\") & (game_data[\"Name\"] != \"TEAM\")]\n",
        "  game_data = game_data.reset_index(drop=True)\n",
        "\n",
        "  #converting to numeric data to let us add other stats for player and team data\n",
        "  #we can see that player info is separated from team info in this case as well \n",
        "  player_info = game_data.iloc[:,0:3]\n",
        "  player_stats = game_data.iloc[:,3:].apply(pd.to_numeric)\n",
        "\n",
        "  team_info = game_results.iloc[:,0]\n",
        "  team_stats = game_results.iloc[:,1:].apply(pd.to_numeric)\n",
        "\n",
        "  game_data = pd.concat([player_info, player_stats], axis=1).reset_index(drop=True)\n",
        "  game_results = pd.concat([team_info, team_stats], axis=1).reset_index(drop=True)\n",
        "\n",
        "  #modify the datasets and add specific columns that were not from turbostats\n",
        "  game_data.insert(10,'Efg%', round(((game_data['Fgm'] + 0.5*game_data['3fgm']) / game_data['Fga']),3))\n",
        "  game_data.insert(11,'Ts%', round(game_data['Points'] / (2 * (game_data['Fga'] + (.475*game_data['Fta']))),3))\n",
        "  game_data.insert(22,'To%', round((game_data['To'] / (game_data['Fga'] + .475*game_data['Fta'] + game_data['To'])),3))\n",
        "\n",
        "\n",
        "  #every other column inserted is opponet stats. this will be useful as these \n",
        "  #are from Dean Oliver's 4 Factors\n",
        "  game_results.insert(8,'Efg%', round(((game_results['Fgm'] + 0.5*game_results['3fgm']) / game_results['Fga']),3))\n",
        "  game_results.insert(9,'Opp_Efg%', list(np.flip(game_results['Efg%'])))\n",
        "  game_results.insert(10,'Ts%', round(game_results['Points'] / (2 * (game_results['Fga'] + (.475*game_results['Fta']))),3))\n",
        "  game_results.insert(11, 'Ft/Fga', round((game_results['Ftm']/game_results['Fga']),3))\n",
        "  game_results.insert(12, 'Opp_Ft/Fga', list(np.flip(game_results['Ft/Fga'])))\n",
        "  game_results.insert(17,'RebO%', round((game_results['RebO']/(game_results['RebO']+list(np.flip(game_results['RebD'])))),3))\n",
        "  game_results.insert(18,'RebD%', round((game_results['RebD']/(game_results['RebD']+list(np.flip(game_results['RebO'])))),3))\n",
        "  game_results.insert(19,'To%', round((game_results['To'] / (game_results['Fga'] + .475*game_results['Fta'] + game_results['To'])),3))\n",
        "  game_results.insert(20,'Opp_To%', list(np.flip(game_results['To%'])))\n",
        "\n",
        "  return [game_data, game_results]\n",
        "\n",
        "def all_datasets():\n",
        "  #team and player data arrays\n",
        "  player_data = []\n",
        "  team_data = []\n",
        "\n",
        "  #start from 1 instead of 0 since the games from turbostats start with 1 \n",
        "  for i in range(1,11):\n",
        "    #if any specifc game is canceled or missing data, use guard if statement\n",
        "    #to do this, look in site link and see game number at the very end\n",
        "    if i == 4:\n",
        "      continue\n",
        "    player, team = dataset(str(i))\n",
        "    player_data.append(player)\n",
        "    team_data.append(team)\n",
        "\n",
        "  #gathers all of the data at the end\n",
        "  player_data = pd.concat(player_data, axis=0).reset_index(drop=True)\n",
        "  team_data = pd.concat(team_data, axis=0).reset_index(drop=True)\n",
        "\n",
        "  return [player_data, team_data]\n",
        "\n",
        "def write_to_excel(path = '/content/drive/MyDrive/2022 PVTO Data Analytics Team'):\n",
        "  combined_player, combined_team = all_datasets()\n",
        "\n",
        "  #creates excel workbook containing all of the PVTO data\n",
        "  writer = pd.ExcelWriter(path + '/PVTOData.xlsx', engine='xlsxwriter')\n",
        "  writer.save()\n",
        "\n",
        "  #puts each of the player and team data into separate sheets\n",
        "  with pd.ExcelWriter(path + '/PVTOData.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "      combined_player.to_excel(writer, sheet_name='PlayerData', index=False)\n",
        "      combined_team.to_excel(writer, sheet_name='TeamData', index=False)\n",
        "  \n",
        "  return 'Workbook uploaded.'\n",
        "\n",
        "#for future use, copy your own computer path and paste it \n",
        "#so that the excel workbook will go straight there\n",
        "write_to_excel()"
      ],
      "metadata": {
        "id": "OpmTvbePAzTc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "5a483a29-c844-4ce7-debf-07c197d79a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Workbook uploaded.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}